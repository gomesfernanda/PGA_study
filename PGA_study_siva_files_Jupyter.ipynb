{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGA files study\n",
    "\n",
    "On this notebook, we'll do some descriptive statistics not on PGA _index_ file, but on the siva files themselves. We want to understand avg/mean/min/max repository size, number of blobs per-repository, avg contribution per-user, etc.\n",
    "\n",
    "The steps I intend to complete to reach the results are:\n",
    "\n",
    "1. Download siva files (following [PGA documentation](https://github.com/src-d/datasets/tree/master/PublicGitArchive/pga))\n",
    "2. Extract siva files (following [siva documentation](https://github.com/src-d/go-siva))\n",
    "3. Query repos using gitbase (following [source{d} documentation](https://docs.sourced.tech/intro/#analyzing-git-repositories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Download siva files\n",
    "\n",
    "We will use the terminal to download the pertinent siva files. I will follow the same criterion as the study on PGA index, so we are interested on repos that has **Jupyter Notebook** files only.\n",
    "\n",
    "To understand how to install PGA and its commands, please follow [the documentation](https://github.com/src-d/datasets/tree/master/PublicGitArchive).\n",
    "\n",
    "```bash\n",
    "$ pga list --lang \"Jupyter Notebook\" -f csv > repos_jupyter.csv\n",
    "```\n",
    "\n",
    "\n",
    "This will give us as output a csv file with the repo's URL, siva filenames for the repo, languages, and much more information. Let's see how the csv looks like.\n",
    "\n",
    "_**NOTE**: since the export of pga doesn't come with the headers on the first row, I manually added on pandas dataframe using the ones from the index, as they are the same._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE_COUNT</th>\n",
       "      <th>COMMITS_COUNT</th>\n",
       "      <th>BRANCHES_COUNT</th>\n",
       "      <th>FORK_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2606.000000</td>\n",
       "      <td>2606.000000</td>\n",
       "      <td>2606.000000</td>\n",
       "      <td>2606.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>471.105909</td>\n",
       "      <td>851.153108</td>\n",
       "      <td>142.298542</td>\n",
       "      <td>1.209133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2274.210560</td>\n",
       "      <td>3229.955311</td>\n",
       "      <td>677.735284</td>\n",
       "      <td>7.520236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>257.750000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70056.000000</td>\n",
       "      <td>79104.000000</td>\n",
       "      <td>14709.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FILE_COUNT  COMMITS_COUNT  BRANCHES_COUNT   FORK_COUNT\n",
       "count   2606.000000    2606.000000     2606.000000  2606.000000\n",
       "mean     471.105909     851.153108      142.298542     1.209133\n",
       "std     2274.210560    3229.955311      677.735284     7.520236\n",
       "min        1.000000       1.000000        2.000000     0.000000\n",
       "25%       25.000000      27.000000        3.000000     0.000000\n",
       "50%       73.000000      95.000000        9.000000     0.000000\n",
       "75%      257.750000     415.000000       48.000000     0.000000\n",
       "max    70056.000000   79104.000000    14709.000000    67.000000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"repos_jupyter.csv\", names=[\"URL\", \"SIVA_FILENAMES\", \"FILE_COUNT\", \"LANGS\", \"LANGS_BYTE_COUNT\", \"LANGS_LINES_COUNT\", \"LANGS_FILES_COUNT\", \"COMMITS_COUNT\", \"BRANCHES_COUNT\", \"FORK_COUNT\", \"EMPTY_LINES_COUNT\", \"CODE_LINES_COUNT\", \"COMMENT_LINES_COUNT\", \"LICENSE\"])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, PGA filtered 2605 repos that has Jupyter Notebook, in line with what we saw when analyzing the index file (PGA index study notebook).\n",
    "\n",
    "Now let's see how many siva files there are.\n",
    "\n",
    "On average, one repo = one siva files, but there can be more than one siva file per repo if there are completely independent branches.\n",
    "\n",
    "To get this number, we'll examine the column B that corresponds to \"SIVA_FILENAMES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6349"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sivafiles = 0\n",
    "\n",
    "for row in df['SIVA_FILENAMES']:\n",
    "    num_sivafiles = row.split(\",\")\n",
    "    count_sivafiles += len(num_sivafiles)\n",
    "\n",
    "count_sivafiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, this is odd. We can see that there are 2,605 repos, but 6,349 siva files. This is not normal at all.\n",
    "\n",
    "Let's understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of siva files is 2.44 with a standard deviation of 64.53\n"
     ]
    }
   ],
   "source": [
    "# We'll create a list that will keep the number of siva files per repo. The lenght of this list will be 2,605.\n",
    "\n",
    "list_sivafiles = []\n",
    "\n",
    "for row in df['SIVA_FILENAMES']:\n",
    "    num_sivafiles = row.split(\",\")\n",
    "    list_sivafiles.append(len(num_sivafiles))\n",
    "\n",
    "# Checking what's the average number of siva files per repo and the standard deviation\n",
    "\n",
    "import statistics\n",
    "average = round(statistics.mean(list_sivafiles), 2)\n",
    "stdev = round(statistics.stdev(list_sivafiles), 2)\n",
    "\n",
    "print(\"The average number of siva files is\", average, \"with a standard deviation of\", stdev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is distorted by some anomaly, since a mean of 2.44 with such great standard deviation is not desireable. Let's keep digging and count the n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:\n",
      "- 2249 repo(s) with 1 siva files\n",
      "- 301 repo(s) with 2 siva files\n",
      "- 40 repo(s) with 3 siva files\n",
      "- 9 repo(s) with 4 siva files\n",
      "- 4 repo(s) with 5 siva files\n",
      "- 1 repo(s) with 6 siva files\n",
      "- 1 repo(s) with 21 siva files\n",
      "- 1 repo(s) with 3295 siva files\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_files = Counter(list_sivafiles)\n",
    "\n",
    "print(\"There are:\")\n",
    "for c in counter_files:\n",
    "    print(\"-\", counter_files[c], \"repo(s) with\", c, \"siva files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOWWWW found the anomaly! This **ONE** repo with 3,295 siva files on it.\n",
    "\n",
    "Now we need to see which repo this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/google/skia-buildbot\n"
     ]
    }
   ],
   "source": [
    "anomaly_sivafiles = max(list_sivafiles)\n",
    "\n",
    "wheres_the_anomaly = [i for i, x in enumerate(list_sivafiles) if x == anomaly_sivafiles][0]\n",
    "\n",
    "print(df.iloc[wheres_the_anomaly]['URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the repo [https://github.com/google/skia-buildbot](https://github.com/google/skia-buildbot) is responsible for 3,295 siva files.\n",
    "\n",
    "For the sake of our current study, we'll leave this repo aside, since it's a HUGE outlier. \n",
    "\n",
    "The new dataframe can be redefined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['URL'] != 'https://github.com/google/skia-buildbot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the siva files corresponding to these repos we'll run the following command on the terminal:\n",
    "\n",
    "```bash\n",
    "$ pga list -l \"Jupyter Notebook\" -f json | jq -r 'select(.url != \"https://github.com/google/skia-buildbot\") | .sivaFilenames[]' | pga get -i -o jupyter_siva_files\n",
    "```\n",
    "\n",
    "What are we doing here?\n",
    "\n",
    "1. using `pga get` command to list the repos that have Jupyter Notebook and resulting in a json file (**stdout**)\n",
    "2. that will be input (**stdin**) for `jq` command (read further [here](https://stedolan.github.io/jq/)) that we will use to filter out the url for the anomaly repo and output the siva filenames (**stdout** again) that\n",
    "3. will serve as the input for `pga get -i` command that will then download the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a much more reasonable outcome, since we're downloading 3,054 files. Lay back and relax, because this will take some time to download. (or go watch some movie, study something else, the download will take hours, I tell you in advance :) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Extract siva files\n",
    "\n",
    "We will follow [go siva documentation](https://github.com/src-d/go-siva) to understand how to (1) install the tool and (2) extract siva files.\n",
    "\n",
    "[EDIT] We actually won't need to extract siva files, since Gitbase is able to read and query siva files!\n",
    "![celebrate](https://media1.giphy.com/media/YTbZzCkRQCEJa/200.webp?cid=3640f6095bc4ab7034554b4f59a77afd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Query repos using gitbase\n",
    "\n",
    "We will use [source{d} engine](https://docs.sourced.tech/engine#quickstart) from now on. The engine enables us to query the repos we just downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
